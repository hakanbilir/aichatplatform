# 17. Per‑Model Breakdown & Latency Metrics (Org Analytics)

> **Audience:** AI coding assistants (Cursor, Claude Code, ChatGPT, etc.) and human developers.  
> **Goal of this file:** Extend the **org‑level analytics** (16.md) with:
>
> - Backend: **per‑model usage & latency breakdown** in the org analytics payload.  
> - Frontend API: updated `OrgUsageSummary` to include `byModel[]`.  
> - Frontend UI: a **Model breakdown & latency** section (bar chart + chips) on the Org Analytics page.  
>
> After following this file, org owners/admins will see **which models consume how many tokens** and **how fast they are (avg & p95 latency)** inside the analytics dashboard.

> **Important instructions to AI agents:**
> - This file **extends and replaces parts of 16.md**. Treat the code here as **canonical**.  
> - Do **not** add TODOs or placeholders; everything must be fully implemented and compilable.  
> - Assume `message.meta.usage` may optionally contain latency (e.g., `latencyMs`), and optionally model name.

---

## 17.1. Analytics Extensions – What We Add

We keep all existing org analytics behavior (16.md) and **add**:

- Per‑model aggregation over the selected time window:
  - `promptTokens`, `completionTokens`, `totalTokens` per model.  
  - `completions` per model.  
  - `avgLatencyMs` (mean) per model.  
  - `p95LatencyMs` per model.
- We derive:
  - Model key: `conversation.model` (preferred) or, as fallback, `meta.usage.model` or `'unknown'`.
  - Latency (ms): from `meta.usage.latencyMs` or, as fallback, `meta.providerMeta.latencyMs` if present.

The API response gets a **new field**:

```ts
byModel: Array<{
  model: string;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  completions: number;
  avgLatencyMs: number;
  p95LatencyMs: number;
}>;
```

Front‑end Org Analytics page will then show:

- A **bar chart** of tokens per model.  
- A set of **chips** showing top models and their average latency in seconds.

---

## 17.2. Backend – Extend `/orgs/:id/usage` with `byModel` & latency

We update the org analytics route to compute per‑model statistics and latency.

> **Important:** This section **replaces** `apps/api-gateway/src/routes/org-analytics.ts` created in 16.md.  
> It keeps all previous behavior and adds per‑model aggregation.

### 17.2.1. Replace `apps/api-gateway/src/routes/org-analytics.ts`

```ts
// apps/api-gateway/src/routes/org-analytics.ts

import { FastifyInstance, FastifyPluginOptions } from 'fastify';
import { prisma } from '@ai-chat/db';
import { JwtPayload } from '../auth/types';
import { z } from 'zod';
import { assertOrgPermission } from '../rbac/guards';

const usageQuerySchema = z.object({
  days: z
    .string()
    .optional()
    .transform((value) => {
      if (!value) return 30;
      const n = Number(value);
      if (!Number.isFinite(n) || n <= 0) return 30;
      if (n > 365) return 365;
      return Math.round(n);
    })
});

export default async function orgAnalyticsRoutes(app: FastifyInstance, _opts: FastifyPluginOptions) {
  // Org-level usage summary (aggregated across all conversations in the org)
  app.get('/orgs/:id/usage', { preHandler: [app.authenticate] }, async (request, reply) => {
    const payload = request.user as JwtPayload;

    const paramsSchema = z.object({ id: z.string().min(1) });
    const parseParams = paramsSchema.safeParse(request.params);
    if (!parseParams.success) {
      return reply.code(400).send({ error: 'Invalid org id' });
    }
    const orgId = parseParams.data.id;

    const parseQuery = usageQuerySchema.safeParse(request.query);
    if (!parseQuery.success) {
      return reply.code(400).send({ error: 'Invalid query', details: parseQuery.error.format() });
    }

    const days = parseQuery.data.days;

    // Enforce RBAC – must have analytics:view on this org
    await assertOrgPermission(
      { id: payload.userId, isSuperadmin: payload.isSuperadmin },
      orgId,
      'analytics:view'
    );

    // Time window
    const now = new Date();
    const from = new Date(now.getTime() - days * 24 * 60 * 60 * 1000);

    // Fetch ASSISTANT messages for this org in the time window, including conversation.model
    const messages = await prisma.message.findMany({
      where: {
        role: 'ASSISTANT',
        createdAt: {
          gte: from
        },
        conversation: {
          orgId
        }
      },
      select: {
        meta: true,
        createdAt: true,
        conversation: {
          select: {
            model: true
          }
        }
      },
      orderBy: {
        createdAt: 'asc'
      }
    });

    let totalPromptTokens = 0;
    let totalCompletionTokens = 0;
    let completions = 0;
    let firstMessageAt: Date | null = null;
    let lastMessageAt: Date | null = null;

    // Prepare per-day buckets
    const dayBuckets = new Map<string, { promptTokens: number; completionTokens: number; totalTokens: number }>();

    // Prepare per-model buckets
    const modelBuckets = new Map<
      string,
      {
        promptTokens: number;
        completionTokens: number;
        totalTokens: number;
        completions: number;
        latencies: number[];
      }
    >();

    for (const m of messages) {
      const meta: any = m.meta ?? {};
      const usage = meta?.usage;

      if (!usage || typeof usage !== 'object') {
        continue;
      }

      const promptTokens = typeof usage.promptTokens === 'number' ? usage.promptTokens : 0;
      const completionTokens = typeof usage.completionTokens === 'number' ? usage.completionTokens : 0;
      const totalTokens = promptTokens + completionTokens;

      totalPromptTokens += promptTokens;
      totalCompletionTokens += completionTokens;
      completions += 1;

      if (!firstMessageAt || m.createdAt < firstMessageAt) {
        firstMessageAt = m.createdAt;
      }
      if (!lastMessageAt || m.createdAt > lastMessageAt) {
        lastMessageAt = m.createdAt;
      }

      const dayKey = m.createdAt.toISOString().slice(0, 10); // YYYY-MM-DD
      const dayExisting = dayBuckets.get(dayKey) ?? {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0
      };

      dayExisting.promptTokens += promptTokens;
      dayExisting.completionTokens += completionTokens;
      dayExisting.totalTokens += totalTokens;

      dayBuckets.set(dayKey, dayExisting);

      // Model key – prefer conversation.model, fallback usage.model, else 'unknown'
      const convModel = m.conversation?.model ?? null;
      const usageModel = typeof (usage as any).model === 'string' ? (usage as any).model : null;
      const modelKey = convModel || usageModel || 'unknown';

      const modelExisting = modelBuckets.get(modelKey) ?? {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
        completions: 0,
        latencies: [] as number[]
      };

      modelExisting.promptTokens += promptTokens;
      modelExisting.completionTokens += completionTokens;
      modelExisting.totalTokens += totalTokens;
      modelExisting.completions += 1;

      // Latency – try usage.latencyMs, then providerMeta.latencyMs
      let latencyMs: number | null = null;
      if (typeof (usage as any).latencyMs === 'number') {
        latencyMs = (usage as any).latencyMs;
      } else if (meta && typeof meta.providerMeta === 'object' && meta.providerMeta !== null) {
        const providerMeta: any = meta.providerMeta;
        if (typeof providerMeta.latencyMs === 'number') {
          latencyMs = providerMeta.latencyMs;
        }
      }

      if (latencyMs !== null && Number.isFinite(latencyMs) && latencyMs >= 0) {
        modelExisting.latencies.push(latencyMs);
      }

      modelBuckets.set(modelKey, modelExisting);
    }

    const byDay = Array.from(dayBuckets.entries())
      .sort(([a], [b]) => (a < b ? -1 : a > b ? 1 : 0))
      .map(([date, stats]) => ({
        date,
        promptTokens: stats.promptTokens,
        completionTokens: stats.completionTokens,
        totalTokens: stats.totalTokens
      }));

    const totals = {
      promptTokens: totalPromptTokens,
      completionTokens: totalCompletionTokens,
      totalTokens: totalPromptTokens + totalCompletionTokens
    };

    const byModel = Array.from(modelBuckets.entries())
      .map(([model, stats]) => {
        let avgLatencyMs = 0;
        let p95LatencyMs = 0;

        if (stats.latencies.length > 0) {
          const sorted = [...stats.latencies].sort((a, b) => a - b);
          const sum = sorted.reduce((acc, v) => acc + v, 0);
          avgLatencyMs = sum / sorted.length;
          const idx = Math.floor(0.95 * (sorted.length - 1));
          p95LatencyMs = sorted[idx] ?? sorted[sorted.length - 1];
        }

        return {
          model,
          promptTokens: stats.promptTokens,
          completionTokens: stats.completionTokens,
          totalTokens: stats.totalTokens,
          completions: stats.completions,
          avgLatencyMs,
          p95LatencyMs
        };
      })
      // Sort by totalTokens desc for convenience
      .sort((a, b) => b.totalTokens - a.totalTokens);

    return reply.send({
      orgId,
      range: {
        from,
        to: now,
        days
      },
      totals,
      completions,
      firstMessageAt,
      lastMessageAt,
      byDay,
      byModel
    });
  });
}
```

This preserves the previous structure and adds a **sorted `byModel` array** with per‑model usage + latency.

---

## 17.3. Frontend API – Extend `OrgUsageSummary` with `byModel`

We now extend the Org Analytics API types to include per‑model buckets.

> **Important:** This section **replaces** `apps/web/src/api/orgAnalytics.ts` created in 16.md.

### 17.3.1. Replace `apps/web/src/api/orgAnalytics.ts`

```ts
// apps/web/src/api/orgAnalytics.ts

import { apiRequest } from './client';

export interface OrgUsageDayBucket {
  date: string; // YYYY-MM-DD
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
}

export interface OrgUsageRange {
  from: string;
  to: string;
  days: number;
}

export interface OrgUsageModelBucket {
  model: string;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  completions: number;
  avgLatencyMs: number;
  p95LatencyMs: number;
}

export interface OrgUsageSummary {
  orgId: string;
  range: OrgUsageRange;
  totals: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  completions: number;
  firstMessageAt: string | null;
  lastMessageAt: string | null;
  byDay: OrgUsageDayBucket[];
  byModel: OrgUsageModelBucket[];
}

export async function getOrgUsageSummary(
  token: string,
  orgId: string,
  days: number
): Promise<OrgUsageSummary> {
  const search = new URLSearchParams({ days: String(days) }).toString();
  return apiRequest<OrgUsageSummary>(`/orgs/${orgId}/usage?${search}`, { method: 'GET' }, token);
}
```

---

## 17.4. Org Analytics UI – Model Breakdown & Latency Section

We extend the Org Analytics page with a **second analytics card** that shows per‑model usage and latency.

> **Important:** This section **replaces** `apps/web/src/orgs/OrgAnalyticsPage.tsx` created in 16.md.  
> It keeps all existing layout & daily tokens chart, and adds a new card.

### 17.4.1. Replace `apps/web/src/orgs/OrgAnalyticsPage.tsx`

```tsx
// apps/web/src/orgs/OrgAnalyticsPage.tsx

import React, { useEffect, useMemo, useState } from 'react';
import {
  Box,
  Typography,
  ToggleButton,
  ToggleButtonGroup,
  Card,
  CardContent,
  Chip,
  CircularProgress,
  Tooltip
} from '@mui/material';
import InsightsIcon from '@mui/icons-material/Insights';
import TimelineIcon from '@mui/icons-material/Timeline';
import GrainIcon from '@mui/icons-material/Grain';
import { useAuth } from '../auth/AuthContext';
import { OrgUsageDayBucket, OrgUsageModelBucket, OrgUsageSummary, getOrgUsageSummary } from '../api/orgAnalytics';
import {
  LineChart,
  Line,
  XAxis,
  YAxis,
  Tooltip as RechartsTooltip,
  ResponsiveContainer,
  CartesianGrid,
  Legend,
  BarChart,
  Bar
} from 'recharts';
import { useParams } from 'react-router-dom';

function formatNumber(n: number): string {
  if (n >= 1_000_000) return `${(n / 1_000_000).toFixed(1)}M`;
  if (n >= 1_000) return `${(n / 1_000).toFixed(1)}k`;
  return String(n);
}

function formatDateLabel(date: string): string {
  // date: YYYY-MM-DD
  return date.slice(5); // MM-DD
}

function formatSeconds(ms: number): string {
  if (!Number.isFinite(ms) || ms <= 0) return '–';
  const s = ms / 1000;
  if (s < 1) return `${s.toFixed(2)}s`;
  if (s < 10) return `${s.toFixed(2)}s`;
  return `${s.toFixed(1)}s`;
}

export const OrgAnalyticsPage: React.FC = () => {
  const { token } = useAuth();
  const { orgId } = useParams<{ orgId: string }>();

  const [days, setDays] = useState<number>(30);
  const [summary, setSummary] = useState<OrgUsageSummary | null>(null);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);

  const handleChangeDays = (_: React.MouseEvent<HTMLElement>, value: number | null) => {
    if (!value) return;
    setDays(value);
  };

  useEffect(() => {
    if (!token || !orgId) {
      setSummary(null);
      return;
    }

    let cancelled = false;

    async function load() {
      setLoading(true);
      setError(null);
      try {
        const data = await getOrgUsageSummary(token, orgId, days);
        if (!cancelled) {
          setSummary(data);
        }
      } catch (err) {
        if (!cancelled) {
          setError((err as Error).message || 'Failed to load org usage');
          setSummary(null);
        }
      } finally {
        if (!cancelled) {
          setLoading(false);
        }
      }
    }

    load();

    return () => {
      cancelled = true;
    };
  }, [token, orgId, days]);

  const chartData = useMemo<OrgUsageDayBucket[]>(() => {
    if (!summary) return [];
    return summary.byDay;
  }, [summary]);

  const modelData = useMemo<OrgUsageModelBucket[]>(() => {
    if (!summary) return [];
    return summary.byModel;
  }, [summary]);

  const topModels = useMemo<OrgUsageModelBucket[]>(() => {
    if (!summary) return [];
    return [...summary.byModel].slice(0, 3);
  }, [summary]);

  const totalTokens = summary?.totals.totalTokens ?? 0;
  const totalPromptTokens = summary?.totals.promptTokens ?? 0;
  const totalCompletionTokens = summary?.totals.completionTokens ?? 0;
  const completions = summary?.completions ?? 0;

  return (
    <Box
      display="flex"
      flexDirection="column"
      flex={1}
      sx={{
        p: 2,
        gap: 2,
        background:
          'radial-gradient(circle at top left, rgba(124,77,255,0.18), transparent 55%), radial-gradient(circle at bottom right, rgba(3,218,198,0.12), transparent 55%)'
      }}
    >
      <Box display="flex" alignItems="center" justifyContent="space-between" mb={1}>
        <Box>
          <Typography variant="h6" sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
            <InsightsIcon fontSize="small" /> Org usage analytics
          </Typography>
          <Typography variant="caption" color="text.secondary">
            Tokens &amp; completions aggregated across all conversations in this organization.
          </Typography>
        </Box>

        <ToggleButtonGroup
          size="small"
          value={days}
          exclusive
          onChange={handleChangeDays}
          aria-label="time window"
        >
          <ToggleButton value={7} aria-label="last 7 days">
            7d
          </ToggleButton>
          <ToggleButton value={30} aria-label="last 30 days">
            30d
          </ToggleButton>
          <ToggleButton value={90} aria-label="last 90 days">
            90d
          </ToggleButton>
        </ToggleButtonGroup>
      </Box>

      {/* Summary cards */}
      <Box display="flex" flexWrap="wrap" gap={2}>
        <Card
          sx={{
            flex: '1 1 220px',
            minWidth: 220,
            borderRadius: 3,
            overflow: 'hidden',
            position: 'relative',
            '&::before': {
              content: '""',
              position: 'absolute',
              inset: 0,
              background: 'linear-gradient(135deg, rgba(124,77,255,0.16), rgba(3,218,198,0.12))',
              opacity: 0.7,
              pointerEvents: 'none'
            }
          }}
        >
          <CardContent sx={{ position: 'relative' }}>
            <Typography variant="caption" color="text.secondary">
              Total tokens
            </Typography>
            <Typography variant="h5" sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
              {loading ? <CircularProgress size={20} /> : formatNumber(totalTokens)}
            </Typography>
            <Typography variant="caption" color="text.secondary">
              Sum of prompt + completion tokens
            </Typography>
          </CardContent>
        </Card>

        <Card
          sx={{
            flex: '1 1 220px',
            minWidth: 220,
            borderRadius: 3,
            overflow: 'hidden'
          }}
        >
          <CardContent>
            <Typography variant="caption" color="text.secondary">
              Prompt tokens
            </Typography>
            <Typography variant="h6">{loading ? <CircularProgress size={18} /> : formatNumber(totalPromptTokens)}</Typography>
            <Typography variant="caption" color="text.secondary">
              Input context used for org queries
            </Typography>
          </CardContent>
        </Card>

        <Card
          sx={{
            flex: '1 1 220px',
            minWidth: 220,
            borderRadius: 3,
            overflow: 'hidden'
          }}
        >
          <CardContent>
            <Typography variant="caption" color="text.secondary">
              Completion tokens
            </Typography>
            <Typography variant="h6">
              {loading ? <CircularProgress size={18} /> : formatNumber(totalCompletionTokens)}
            </Typography>
            <Typography variant="caption" color="text.secondary">
              Generated output across all chats
            </Typography>
          </CardContent>
        </Card>

        <Card
          sx={{
            flex: '1 1 220px',
            minWidth: 220,
            borderRadius: 3,
            overflow: 'hidden'
          }}
        >
          <CardContent>
            <Typography variant="caption" color="text.secondary">
              Completions
            </Typography>
            <Typography variant="h6">
              {loading ? <CircularProgress size={18} /> : completions}
            </Typography>
            <Typography variant="caption" color="text.secondary">
              Number of assistant responses with usage
            </Typography>
          </CardContent>
        </Card>
      </Box>

      {/* Daily tokens chart */}
      <Card
        sx={{
          mt: 2,
          flex: 1,
          minHeight: 260,
          borderRadius: 3,
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        <CardContent sx={{ flex: 1, display: 'flex', flexDirection: 'column', gap: 1 }}>
          <Box display="flex" alignItems="center" justifyContent="space-between" mb={1}>
            <Box display="flex" alignItems="center" gap={1}>
              <TimelineIcon fontSize="small" />
              <Typography variant="subtitle2">Daily tokens</Typography>
            </Box>
            <Box display="flex" alignItems="center" gap={1}>
              <Tooltip title="Each point represents a day within the selected window">
                <Chip
                  size="small"
                  icon={<GrainIcon sx={{ fontSize: 16 }} />}
                  label={`${days}d window`}
                  variant="outlined"
                  sx={{ height: 24, fontSize: 11 }}
                />
              </Tooltip>
            </Box>
          </Box>

          {loading && !summary ? (
            <Box flex={1} display="flex" alignItems="center" justifyContent="center">
              <CircularProgress />
            </Box>
          ) : error ? (
            <Box flex={1} display="flex" alignItems="center" justifyContent="center">
              <Typography variant="body2" color="error">
                {error}
              </Typography>
            </Box>
          ) : chartData.length === 0 ? (
            <Box flex={1} display="flex" alignItems="center" justifyContent="center">
              <Typography variant="body2" color="text.secondary">
                No usage data in this window.
              </Typography>
            </Box>
          ) : (
            <Box flex={1} sx={{ minHeight: 220 }}>
              <ResponsiveContainer width="100%" height="100%">
                <LineChart data={chartData} margin={{ top: 8, right: 16, bottom: 8, left: 0 }}>
                  <CartesianGrid strokeDasharray="3 3" opacity={0.2} />
                  <XAxis dataKey="date" tickFormatter={formatDateLabel} tick={{ fontSize: 11 }} />
                  <YAxis tick={{ fontSize: 11 }} />
                  <RechartsTooltip
                    formatter={(value: any, name: any) => [value, name]}
                    labelFormatter={(label) => `Date: ${label}`}
                  />
                  <Legend />
                  <Line type="monotone" dataKey="promptTokens" name="Prompt tokens" dot={false} strokeWidth={2} />
                  <Line
                    type="monotone"
                    dataKey="completionTokens"
                    name="Completion tokens"
                    dot={false}
                    strokeWidth={2}
                  />
                  <Line type="monotone" dataKey="totalTokens" name="Total tokens" dot={false} strokeWidth={2} />
                </LineChart>
              </ResponsiveContainer>
            </Box>
          )}
        </CardContent>
      </Card>

      {/* Model breakdown & latency */}
      <Card
        sx={{
          mt: 2,
          flex: 1,
          minHeight: 260,
          borderRadius: 3,
          display: 'flex',
          flexDirection: 'column'
        }}
      >
        <CardContent sx={{ flex: 1, display: 'flex', flexDirection: 'column', gap: 2 }}>
          <Box display="flex" alignItems="center" justifyContent="space-between">
            <Box>
              <Typography variant="subtitle2">Model breakdown &amp; latency</Typography>
              <Typography variant="caption" color="text.secondary">
                Compare token usage and response times across models in this org.
              </Typography>
            </Box>
            <Box display="flex" alignItems="center" gap={1} flexWrap="wrap">
              {topModels.map((m) => (
                <Chip
                  key={m.model}
                  size="small"
                  label={`${m.model} · avg ${formatSeconds(m.avgLatencyMs)} · p95 ${formatSeconds(m.p95LatencyMs)}`}
                  variant="outlined"
                  sx={{ height: 24, fontSize: 11 }}
                />
              ))}
            </Box>
          </Box>

          {loading && !summary ? (
            <Box flex={1} display="flex" alignItems="center" justifyContent="center">
              <CircularProgress />
            </Box>
          ) : modelData.length === 0 ? (
            <Box flex={1} display="flex" alignItems="center" justifyContent="center">
              <Typography variant="body2" color="text.secondary">
                No per-model usage data available in this window.
              </Typography>
            </Box>
          ) : (
            <Box flex={1} sx={{ minHeight: 220 }}>
              <ResponsiveContainer width="100%" height="100%">
                <BarChart
                  data={modelData}
                  layout="vertical"
                  margin={{ top: 8, right: 16, bottom: 8, left: 40 }}
                >
                  <CartesianGrid strokeDasharray="3 3" opacity={0.2} />
                  <XAxis type="number" tickFormatter={formatNumber} tick={{ fontSize: 11 }} />
                  <YAxis type="category" dataKey="model" tick={{ fontSize: 11 }} />
                  <RechartsTooltip
                    formatter={(value: any, name: any) => [formatNumber(value as number), name]}
                    labelFormatter={(label) => `Model: ${label}`}
                  />
                  <Legend />
                  <Bar dataKey="totalTokens" name="Total tokens" />
                </BarChart>
              </ResponsiveContainer>
            </Box>
          )}
        </CardContent>
      </Card>
    </Box>
  );
};
```

This UI keeps the existing **daily tokens line chart** and adds a **second, vertical bar chart** showing tokens per model, plus latency chips for the top 3 models.

---

## 17.5. Sanity Checks

From the repo root:

1. **Install dependencies (if not already):**

   ```bash
   pnpm install
   ```

2. **Run API gateway:**

   ```bash
   pnpm dev --filter=api-gateway
   ```

3. **Verify backend response includes `byModel`:**

   ```bash
   curl -H "Authorization: Bearer <token>" \
     "http://localhost:4000/orgs/<orgId>/usage?days=30"
   ```

   You should see:

   - `byDay` (unchanged)  
   - `byModel` array with `model`, `totalTokens`, `completions`, `avgLatencyMs`, `p95LatencyMs`.

4. **Run web app:**

   ```bash
   cd apps/web
   pnpm dev
   ```

5. **Verify Org Analytics UI:**

   - Navigate to `/app/orgs/<orgId>/analytics`.  
   - Check that:
     - Top cards still show totals.  
     - "Daily tokens" chart works as before.  
     - New "Model breakdown & latency" card appears.  
     - Chips show top models with readable average / p95 latency.  
     - Bar chart shows total tokens per model; hover shows tooltips with exact values.

If all checks pass, your org analytics dashboard now provides **model‑level introspection and latency insights**, which is a key capability for production‑grade, multi‑model AI platforms.

---

## 17.6. Next Steps

Future markdown files can build on this by:

- Adding **per‑model daily series** (stacked area chart) to track model mix over time.  
- Introducing **per‑org quotas** with soft/hard limits and warning banners when approaching limits.  
- Exposing a **downloadable CSV/JSON** of usage and latency for external BI tools.

> **AI Agent Instruction:**  
> Before moving on, ensure `/orgs/:id/usage` returns the new `byModel` field and that `OrgAnalyticsPage` compiles and renders the new card correctly.

---

_End of 17.md – Per‑Model Breakdown & Latency Metrics (Org Analytics)_
