# 33. Knowledge Base, Document Ingestion & RAG Retrieval

> **Audience:** AI coding assistants (Cursor, Claude Code, ChatGPT, etc.) and human backend/frontend engineers.  
> **Goal of this file:** Add a **first‑class knowledge base (KB) / RAG** layer to the AI chat platform so that:
>
> - Orgs can upload documents, URLs and text snippets as a **knowledge base**.  
> - The system can **chunk, embed, store and search** these documents.  
> - Chat turns can optionally use **RAG retrieval** to enrich prompts.  
> - All of this is **multi‑tenant** (org‑scoped) and integrated with RBAC and tools.
>
> This file focuses on **backend models, services and APIs**, with clear enough contracts that a future UI md file can easily consume.

This file builds on:

- 13.md – Role & RBAC model.  
- 19.md – Org quota / usage guard.  
- 25–26.md – Chat engine & tools.  
- 28.md – Observability.  
- 30.md – Deployment/config.  
- 31.md – Security & multi‑tenant isolation.

---

## 33.1. Concepts & Terminology

We introduce the **Knowledge Base** concept per organization.

Core ideas:

- **Knowledge Space** – a logical bucket of content within an org (e.g. "Product Docs", "HR Policies", "Customer ACME").  
- **Source** – the origin of content (file upload, URL, Slack export, etc.).  
- **Document** – a high‑level ingest unit (e.g. one PDF, one web page, one Markdown file).  
- **Chunk** – a small text segment (e.g. 256–1,024 tokens) that is embedded and stored for retrieval.  
- **Embedding Job** – an asynchronous or synchronous process that generates vector embeddings for chunks.

Constraints:

- Everything is **orgId‑scoped**, aligned with 31.4.  
- Embeddings can be produced by any provider (OpenAI, local model, custom embeddings). We abstract this as an `EmbeddingProvider` interface.  
- Retrieval is used as an internal **tool** by the chat engine (RAG), not exposed directly as an external tool.

---

## 33.2. Prisma Data Model

We add minimal Prisma models for the KB (you can extend later).

```prisma
model KnowledgeSpace {
  id        String   @id @default(cuid())
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  orgId     String
  name      String
  slug      String
  isDefault Boolean  @default(false)

  org       Org      @relation(fields: [orgId], references: [id])
  documents KnowledgeDocument[]
}

model KnowledgeDocument {
  id            String   @id @default(cuid())
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt

  orgId         String
  spaceId       String
  title         String
  sourceType    String   // e.g. "upload", "url", "slack"
  sourceUrl     String?  // if applicable
  originalName  String?  // filename, etc.
  mimeType      String?
  sizeBytes     Int?

  status        String   // e.g. "pending", "ingested", "error"
  statusMessage String?

  org   Org             @relation(fields: [orgId], references: [id])
  space KnowledgeSpace  @relation(fields: [spaceId], references: [id])

  chunks KnowledgeChunk[]
}

model KnowledgeChunk {
  id          String   @id @default(cuid())
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  orgId       String
  documentId  String
  index       Int
  text        String
  embedding   Bytes?

  org      Org               @relation(fields: [orgId], references: [id])
  document KnowledgeDocument  @relation(fields: [documentId], references: [id])
}

model EmbeddingJob {
  id          String   @id @default(cuid())
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  orgId       String
  spaceId     String
  documentId  String
  status      String   // "pending", "running", "completed", "failed"
  error       String?
}
```

These models allow:

- Multiple spaces per org.  
- Each document broken into ordered chunks with optional embeddings.  
- Tracking of ingestion/embedding jobs.

---

## 33.3. Embedding Provider Abstraction

We define a small abstraction for generating embeddings.

### 33.3.1. Types

**File:** `apps/api-gateway/src/knowledge/embeddings.ts`

```ts
// apps/api-gateway/src/knowledge/embeddings.ts

export interface EmbeddingProviderConfig {
  model: string;
}

export interface EmbeddingProvider {
  embed(texts: string[]): Promise<number[][]>;
}

export function getDefaultEmbeddingProvider(): {
  provider: EmbeddingProvider;
  config: EmbeddingProviderConfig;
} {
  // Placeholder: hook into OpenAI, local model, etc.
  // Implementations may read env vars like EMBEDDING_API_KEY, EMBEDDING_MODEL.
  const config: EmbeddingProviderConfig = {
    model: process.env.EMBEDDING_MODEL || 'text-embedding-3-small'
  };

  const provider: EmbeddingProvider = {
    async embed(texts: string[]): Promise<number[][]> {
      // Implement using your chosen backend. For now, throw to force implementation.
      throw new Error('Embedding provider not implemented');
    }
  };

  return { provider, config };
}
```

> **AI agent note:** When implementing for real, you can plug in OpenAI, a self‑hosted embedding endpoint or an Ollama‑backed embedding model.

---

## 33.4. Chunking & Ingestion Service

We implement a service that:

1. Takes raw text for a `KnowledgeDocument`.  
2. Splits it into chunks.  
3. Optionally computes embeddings.  
4. Writes `KnowledgeChunk` rows and updates document/job status.

### 33.4.1. Chunking Utility

**File:** `apps/api-gateway/src/knowledge/chunkText.ts`

```ts
// apps/api-gateway/src/knowledge/chunkText.ts

export interface ChunkOptions {
  maxChars?: number; // rough heuristic; refine later by tokens if needed
}

export function chunkText(text: string, options: ChunkOptions = {}): string[] {
  const maxChars = options.maxChars ?? 1500;

  const chunks: string[] = [];
  let current = '';

  const sentences = text.split(/(?<=[.!?])\s+/);

  for (const sentence of sentences) {
    if ((current + ' ' + sentence).length > maxChars) {
      if (current.trim().length > 0) {
        chunks.push(current.trim());
      }
      current = sentence;
    } else {
      current = current ? current + ' ' + sentence : sentence;
    }
  }

  if (current.trim().length > 0) {
    chunks.push(current.trim());
  }

  return chunks;
}
```

### 33.4.2. Ingestion Service

**File:** `apps/api-gateway/src/services/knowledgeIngestion.ts`

```ts
// apps/api-gateway/src/services/knowledgeIngestion.ts

import { prisma } from '@ai-chat/db';
import { chunkText } from '../knowledge/chunkText';
import { getDefaultEmbeddingProvider } from '../knowledge/embeddings';
import { logger } from '../observability/logger';

export async function ingestDocumentFromText(params: {
  orgId: string;
  spaceId: string;
  title: string;
  text: string;
  sourceType?: string;
  sourceUrl?: string | null;
}): Promise<{ documentId: string }> {
  const doc = await prisma.knowledgeDocument.create({
    data: {
      orgId: params.orgId,
      spaceId: params.spaceId,
      title: params.title,
      sourceType: params.sourceType ?? 'api',
      sourceUrl: params.sourceUrl ?? null,
      status: 'pending'
    }
  });

  const job = await prisma.embeddingJob.create({
    data: {
      orgId: params.orgId,
      spaceId: params.spaceId,
      documentId: doc.id,
      status: 'pending'
    }
  });

  // Synchronous ingestion (for now). For large docs, move to a background queue.
  try {
    await runEmbeddingJob(job.id);
  } catch (err) {
    logger.error({
      event: 'knowledge.ingest.error',
      orgId: params.orgId,
      documentId: doc.id,
      error: (err as Error).message
    }, 'Knowledge ingestion failed');
  }

  return { documentId: doc.id };
}

export async function runEmbeddingJob(jobId: string): Promise<void> {
  const job = await prisma.embeddingJob.findUnique({ where: { id: jobId } });
  if (!job) {
    throw new Error('Embedding job not found');
  }

  await prisma.embeddingJob.update({
    where: { id: job.id },
    data: { status: 'running', error: null }
  });

  const doc = await prisma.knowledgeDocument.findUnique({
    where: { id: job.documentId }
  });

  if (!doc) {
    throw new Error('Document not found for embedding job');
  }

  // For now, assume the raw text is stored in a separate table or object store.
  // In a minimal example, you might store text directly on the document.
  const rawText = (doc as any).text ?? '';

  const chunks = chunkText(rawText, { maxChars: 1500 });

  const { provider } = getDefaultEmbeddingProvider();

  // If provider is not implemented, this will throw; you can skip embeddings initially.
  const embeddings = await provider.embed(chunks);

  const records = chunks.map((chunk, index) => ({
    orgId: doc.orgId,
    documentId: doc.id,
    index,
    text: chunk,
    embedding: Buffer.from(new Float32Array(embeddings[index]).buffer)
  }));

  await prisma.$transaction([
    prisma.knowledgeChunk.deleteMany({ where: { documentId: doc.id } }),
    prisma.knowledgeChunk.createMany({ data: records }),
    prisma.knowledgeDocument.update({
      where: { id: doc.id },
      data: {
        status: 'ingested',
        statusMessage: null
      }
    }),
    prisma.embeddingJob.update({
      where: { id: job.id },
      data: { status: 'completed', error: null }
    })
  ]);
}
```

> **Note:** For large documents, you should offload `runEmbeddingJob` to a background worker (outside of HTTP request lifecycle).

---

## 33.5. Retrieval Service (RAG)

We implement a retrieval function that given a query string + org/space, returns top K chunks.

### 33.5.1. Vector Search Strategy

- Minimal implementation: load embeddings into memory and compute cosine similarity in Node.  
- Production: use a vector‑aware DB (Postgres + pgvector, Qdrant, Weaviate, etc.) and call its similarity search.

Below is a simple **in‑process** example using pgvector‑style SQL (if you use Postgres + pgvector).

### 33.5.2. Retrieval Code

**File:** `apps/api-gateway/src/services/knowledgeRetrieval.ts`

```ts
// apps/api-gateway/src/services/knowledgeRetrieval.ts

import { prisma } from '@ai-chat/db';
import { getDefaultEmbeddingProvider } from '../knowledge/embeddings';

export interface RetrievedChunk {
  chunkId: string;
  documentId: string;
  text: string;
  score: number;
}

export async function retrieveRelevantChunks(params: {
  orgId: string;
  spaceId?: string | null;
  query: string;
  limit?: number;
}): Promise<RetrievedChunk[]> {
  const { provider } = getDefaultEmbeddingProvider();

  const [queryEmbedding] = await provider.embed([params.query]);
  const limit = params.limit ?? 8;

  // Example for pgvector; adjust to your stack.
  // Assumes you have a vector column or use raw bytes and convert.

  const rows = await prisma.$queryRawUnsafe<any[]>(
    `
    SELECT id, "documentId", text,
           1 - (embedding <=> $1::vector) AS score
    FROM "KnowledgeChunk"
    WHERE "orgId" = $2
      ${params.spaceId ? 'AND "documentId" IN (SELECT id FROM "KnowledgeDocument" WHERE "spaceId" = $3)' : ''}
    ORDER BY embedding <=> $1::vector
    LIMIT $4
    `,
    queryEmbedding,
    params.orgId,
    params.spaceId ?? undefined,
    limit
  );

  return rows.map((row) => ({
    chunkId: row.id,
    documentId: row.documentId,
    text: row.text,
    score: Number(row.score)
  }));
}
```

> **AI agent note:** If you don’t have pgvector, replace this with your vector DB client or in‑memory similarity calculation for smaller setups.

---

## 33.6. HTTP API for Knowledge Spaces & Documents

We expose minimal routes for:

- Listing spaces.  
- Creating a space.  
- Ingesting a text document (simple case).  
- Triggering retrieval (for testing).

### 33.6.1. Service for Spaces

**File:** `apps/api-gateway/src/services/knowledgeSpaces.ts`

```ts
// apps/api-gateway/src/services/knowledgeSpaces.ts

import { prisma } from '@ai-chat/db';

export async function listSpaces(orgId: string) {
  return prisma.knowledgeSpace.findMany({
    where: { orgId },
    orderBy: { createdAt: 'asc' }
  });
}

export async function createSpace(orgId: string, name: string): Promise<{ id: string }> {
  const slug = name
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '')
    .slice(0, 64);

  const space = await prisma.knowledgeSpace.create({
    data: {
      orgId,
      name,
      slug
    }
  });

  return { id: space.id };
}
```

### 33.6.2. Routes

**File:** `apps/api-gateway/src/routes/knowledge.ts`

```ts
// apps/api-gateway/src/routes/knowledge.ts

import { FastifyInstance, FastifyPluginOptions } from 'fastify';
import { z } from 'zod';
import { JwtPayload } from '../auth/types';
import { assertOrgPermission } from '../rbac/guards';
import { createSpace, listSpaces } from '../services/knowledgeSpaces';
import { ingestDocumentFromText } from '../services/knowledgeIngestion';
import { retrieveRelevantChunks } from '../services/knowledgeRetrieval';

const createSpaceBodySchema = z.object({
  name: z.string().min(1).max(128)
});

const ingestBodySchema = z.object({
  spaceId: z.string().min(1),
  title: z.string().min(1).max(256),
  text: z.string().min(1)
});

const retrieveQuerySchema = z.object({
  spaceId: z.string().optional(),
  query: z.string().min(1),
  limit: z
    .string()
    .optional()
    .transform((val) => (val ? parseInt(val, 10) : undefined))
    .refine((val) => !val || !Number.isNaN(val), { message: 'limit must be a number' })
});

export default async function knowledgeRoutes(app: FastifyInstance, _opts: FastifyPluginOptions) {
  // List spaces
  app.get('/orgs/:orgId/knowledge/spaces', { preHandler: [app.authenticate] }, async (request, reply) => {
    const payload = request.user as JwtPayload;
    const orgId = (request.params as any).orgId as string;

    await assertOrgPermission(
      { id: payload.userId, isSuperadmin: payload.isSuperadmin },
      orgId,
      'org:chat:read'
    );

    const spaces = await listSpaces(orgId);
    return reply.send({ spaces });
  });

  // Create space
  app.post('/orgs/:orgId/knowledge/spaces', { preHandler: [app.authenticate] }, async (request, reply) => {
    const payload = request.user as JwtPayload;
    const orgId = (request.params as any).orgId as string;

    await assertOrgPermission(
      { id: payload.userId, isSuperadmin: payload.isSuperadmin },
      orgId,
      'org:settings:manage'
    );

    const parsed = createSpaceBodySchema.safeParse(request.body);
    if (!parsed.success) {
      return reply.code(400).send({ error: 'INVALID_BODY', details: parsed.error.format() });
    }

    const space = await createSpace(orgId, parsed.data.name);
    return reply.code(201).send(space);
  });

  // Ingest text
  app.post('/orgs/:orgId/knowledge/documents:text', { preHandler: [app.authenticate] }, async (request, reply) => {
    const payload = request.user as JwtPayload;
    const orgId = (request.params as any).orgId as string;

    await assertOrgPermission(
      { id: payload.userId, isSuperadmin: payload.isSuperadmin },
      orgId,
      'org:chat:write'
    );

    const parsed = ingestBodySchema.safeParse(request.body);
    if (!parsed.success) {
      return reply.code(400).send({ error: 'INVALID_BODY', details: parsed.error.format() });
    }

    const { spaceId, title, text } = parsed.data;

    const result = await ingestDocumentFromText({
      orgId,
      spaceId,
      title,
      text,
      sourceType: 'api'
    });

    return reply.code(202).send(result);
  });

  // Test retrieval endpoint
  app.get('/orgs/:orgId/knowledge/retrieve', { preHandler: [app.authenticate] }, async (request, reply) => {
    const payload = request.user as JwtPayload;
    const orgId = (request.params as any).orgId as string;

    await assertOrgPermission(
      { id: payload.userId, isSuperadmin: payload.isSuperadmin },
      orgId,
      'org:chat:read'
    );

    const parsed = retrieveQuerySchema.safeParse(request.query);
    if (!parsed.success) {
      return reply.code(400).send({ error: 'INVALID_QUERY', details: parsed.error.format() });
    }

    const chunks = await retrieveRelevantChunks({
      orgId,
      spaceId: parsed.data.spaceId,
      query: parsed.data.query,
      limit: parsed.data.limit
    });

    return reply.send({ chunks });
  });
}
```

Register in `main.ts`:

```ts
import knowledgeRoutes from './routes/knowledge';

await app.register(knowledgeRoutes);
```

---

## 33.7. RAG Integration into Chat Engine

We integrate retrieval as an **optional pre‑step** for chat turns.

### 33.7.1. Conversation Settings

Extend the `Conversation` model (or its settings JSON) to include:

- `ragEnabled: boolean`  
- `ragSpaceId: string | null`  
- `ragMaxChunks: number` (e.g. 4–8)

This may already live in a `conversation.settings` JSON column; if so, extend that schema such that:

```ts
interface ConversationRagSettings {
  enabled: boolean;
  spaceId: string | null;
  maxChunks: number; // default 4
}
```

### 33.7.2. Retrieval Hook in `runConversationTurn`

In `apps/api-gateway/src/services/chatEngine.ts` (25–26.md), after loading the conversation and before calling the model:

```ts
import { retrieveRelevantChunks } from '../services/knowledgeRetrieval';

// ... inside runConversationTurn

let ragContextText: string | null = null;

if (conversation.settings?.rag?.enabled) {
  const maxChunks = conversation.settings.rag.maxChunks ?? 4;

  const chunks = await retrieveRelevantChunks({
    orgId: conversation.orgId!,
    spaceId: conversation.settings.rag.spaceId,
    query: userMessageContent, // The latest user message content
    limit: maxChunks
  });

  if (chunks.length > 0) {
    ragContextText = chunks
      .map((c) => c.text)
      .join('\n\n');
  }
}
```

Then, when constructing the `messages` array sent to the model, prepend a system message if `ragContextText` exists:

```ts
if (ragContextText) {
  baseMessages.unshift({
    role: 'system',
    content:
      'You have access to the following knowledge base context. Use it to answer the user question. ' +
      'If the context does not contain the answer, say so explicitly.\n\n' +
      ragContextText
  });
}
```

This ensures RAG context is available but optional.

---

## 33.8. Security, Quota & Observability Considerations

- **Org scoping** is enforced on all KB queries (`orgId` in where clause).  
- `assertOrgPermission` is used for all endpoints (read vs write).  
- Embedding generation should be counted against **org token/quota** (19.md) if using paid providers.  
- Observability (28.md): add logs and metrics for:
  - `knowledge.ingest.started` / `knowledge.ingest.completed`  
  - `knowledge.retrieve` with latency and number of chunks.  
- Analytics (29.md): you may later extend `OrgAnalytics` to include KB usage (docs count, chunks, retrievals per org).

---

## 33.9. Sanity Checks

From repo root:

1. **Migrate schema:**

   ```bash
   pnpm --filter api-gateway prisma migrate dev
   ```

2. **Implement embedding provider** (or temporarily stub it):

   - Update `getDefaultEmbeddingProvider()` with a real backend.  
   - Or temporarily skip embeddings and store only chunks (adjust retrieval accordingly).

3. **Typecheck & lint:**

   ```bash
   pnpm lint
   pnpm typecheck
   ```

4. **Run API & test endpoints:**

   - Create a space: `POST /orgs/:orgId/knowledge/spaces`.  
   - Ingest text: `POST /orgs/:orgId/knowledge/documents:text`.  
   - Retrieve: `GET /orgs/:orgId/knowledge/retrieve?query=...`.  
   - Enable RAG on a conversation (via settings) and verify model prompts now include KB context.

If all checks pass and embeddings are wired, your AI chat platform now has a **multi‑tenant, org‑scoped knowledge base** with proper ingestion and RAG retrieval, ready for UI integration and advanced product features (search, KB browsers, auto‑linking to sources, etc.).

---

_End of 33.md – Knowledge Base, Document Ingestion & RAG Retrieval_
